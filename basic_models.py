import pickle
import argparse
import numpy as np
import sklearn
import pandas as pd
import sklearn.feature_extraction.text
import sklearn.svm
import sklearn.linear_model
import sklearn.naive_bayes
from sklearn.preprocessing import LabelEncoder, OneHotEncoder


#An n-gram model is a probabilistic language model used in natural language processing (NLP) and text analysis. It's based on the idea that the probability of a word occurring in a sequence depends not only on the previous word but also on the previous (n-1) words.
def genFeature(train_text, valid_text, test_text, max_ngram = 2):
#n-gram features generated by techniques such as CountVectorizer or TfidfVectorizer can be used as input features for various machine learning models, including Support Vector Machines (SVMs) like SVC (Support Vector Classifier).
    def make_list(texts):
        res = []
        for t in texts:
            res.append(' '.join(t))
        return res
    print("Creating N-gram: ")
    tra_text = make_list(train_text)
    val_text = make_list(valid_text)
    te_text = make_list(test_text)
    all_texts = tra_text + val_text + te_text

    gen = sklearn.feature_extraction.text.CountVectorizer(ngram_range = (1, max_ngram), analyzer = 'word')
    gen.fit(all_texts)
    train_features = gen.transform(tra_text)
    valid_features = gen.transform(val_text)
    test_features = gen.transform(te_text)

    return train_features, valid_features, test_features

def basic_model(x, y, test_x, test_y, model_Name = 'svc'):
    if model_Name == 'svc':
        model = sklearn.svm.SVC(probability = True)
    elif model_Name == 'linear svc':
        model = sklearn.svm.LinearSVC()
    elif model_Name == 'logistic':
        model = sklearn.linear_model.LogisticRegression(n_jobs = 2)
    elif model_Name == 'naive bayes':
        model = sklearn.naive_bayes.MultinomiaNB()


    model.fit(x, y)
    test_y_est = model.predict(test_x)
    clssifier_report = sklearn.metrics.classification_report(test_y, test_y_est, digits = 3)
    accuracy = sklearn.metrics.accuracy_score(test_y, test_y_est)
    print("lllalla")
    label_encoder = LabelEncoder()
    test_y_encoded = label_encoder.fit_transform(test_y)
    test_y_est_encoded = label_encoder.transform(test_y_est)

    auc_score = sklearn.metrics.roc_auc_score(test_y_encoded, test_y_est_encoded)
    #plot ROC
    false_posi_rate, true_posi_rate, thresholds = sklearn.metrics.roc_curve(test_y_encoded, test_y_est_encoded)
    return accuracy, auc_score



def main():

    global args
    parser = argparse.ArgumentParser(
        description=__doc__,
        formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('--data', help="The input file", type=str, default='train_val_test_data.pkl')
    parser.add_argument('--ngram', help="Maximum ngram length", type=int, default=3)
    parser.add_argument('--model', help="model name", type=str, default='svc')

    args = parser.parse_args()
 
    #Load data from pickle file
    file_path = 'data.pickle'
    train_text, train_cond, val_text, val_cond, test_text, test_cond = pd.read_pickle(args.data)
    accuracies = {}
    aucs = {}
    train_features, val_features, test_features = genFeature(train_text, val_text, test_text, max_ngram = args.ngram)

    conditions = ['cohort', 
                  'Obesity', 
                  'Non_Adherence', 
                  'Developmental_Delay_Retardation',
                  'Advanced_Heart_Disease',
                  'Advanced_Lung_Disease', 
                  'Schizophrenia_and_other_Psychiatric_Disorders', 
                  'Alcohol_Abuse', 
                  'Other_Substance_Abuse', 
                  'Chronic_Pain_Fibromyalgia', 
                  'Chronic_Neurological_Dystrophies', 
                  'Advanced_Cancer', 
                  'Depression', 
                  'Dementia', 
                  'Unsure'] 



    for i, j in enumerate(conditions):
        print("Start to working on condition {}".format(j))
        train_y = train_cond[:, i]
        test_y = test_cond[:, i]
        accuracy, auc_score = basic_model(train_features, train_y, test_features, test_y)
        accuracies[j] = accuracy
        aucs[j] = auc_score

    print('accuracy: {}'.format(accuracies))
    print('auc: {}'.format(aucs))
    # with open("args.data", 'rb') as f:
    #     data = pickle.load(f)

    # Display the loaded data
    # for line in data[:5]:
    #     print(line)


    # all_accs = []
    # all_aucs = []

    # with h5py.File(args.data, "r") as f:
    #     if not os.path.isfile(os.path.join("converted/X_features-"+str(args.ngram)+".npz")):
    #         print('Computing features.')
    #         train_x = f["train"][:]
    #         valid_x = f["val"][:]
    #         test_x = f["test"][:]

    #         X_features, val_X_features, test_X_features = extract_features(train_x, valid_x, test_x, args.ngram)
    #     else:
    #         print('Skipping Build of Ngrams: model already exists.')
    #         X_features = dict(np.load(os.path.join("converted", "X_features-"+str(args.ngram)+".npz")))['features'].item()
    #         val_X_features = dict(np.load(os.path.join("converted", "val_X_features-"+str(args.ngram)+".npz")))['features'].item()
    #         test_X_features = dict(np.load(os.path.join("converted", "test_X_features-"+str(args.ngram)+".npz")))['features'].item()




    #     for index, condition in enumerate(conditions):
    #         # for dataset_filepath in sorted(glob.glob(os.path.join(data_folder_formatted, 'icu_frequent_flyers_cohort.npz'))):

    #         print('Current Condition: {0}'.format(condition))

    #         train_y = f["train_label"][:,index]
    #         valid_y = f["val_label"][:,index]
    #         test_y = f["test_label"][:,index]
    #         current_accs = []
    #         current_aucs = []
    #         #for subset in xrange(1,21):
    #         #    s = subset/float(20)
    #         acc, auc = make_predictions(X_features, train_y, val_X_features, valid_y, test_X_features, test_y, 1)#s)
    #         current_accs.append(acc)
    #         current_aucs.append(auc)
    #         print('\n')
          

if __name__ == "__main__":
    main()
